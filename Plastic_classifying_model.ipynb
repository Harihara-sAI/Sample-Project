{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+bRqq6GjtiLB///ZwGMy2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harihara-sAI/Sample-Project/blob/main/Plastic_classifying_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB_UgPUwdnZr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "plt.style.use('classic')\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils import normalize, to_categorical\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "image_directory = 'drive/MyDrive/Data/Images/'\n",
        "SIZE = 200\n",
        "dataset = []\n",
        "label = []\n",
        "pet_images = os.listdir(image_directory + 'PET/')\n",
        "for i, image_name in enumerate(pet_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread(image_directory + 'PET/' + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        dataset.append(np.array(image))\n",
        "        label.append(0)\n",
        "\n",
        "pehd_images = os.listdir(image_directory + 'PEHD/')\n",
        "for i, image_name in enumerate(pehd_images):\n",
        "\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread(image_directory + 'PEHD/' + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        dataset.append(np.array(image))\n",
        "        label.append(1)\n",
        "\n",
        "pp_images = os.listdir(image_directory + 'PP/')\n",
        "for i, image_name in enumerate(pp_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread(image_directory + 'PP/' + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        dataset.append(np.array(image))\n",
        "        label.append(2)\n",
        "dataset = np.array(dataset)\n",
        "label = np.array(label)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)\n",
        "\n",
        "\n",
        "num_classes = 3\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(SIZE,SIZE, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "epochs=10\n",
        "history = model.fit(\n",
        "  X_train,y_train,\n",
        "  validation_data=(X_test,y_test),\n",
        "  epochs=epochs\n",
        ")\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range,acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range,val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range,loss, label='Training Loss')\n",
        "plt.plot(epochs_range,val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ]
}